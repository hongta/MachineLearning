{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get images\n",
    "image = img_to_array(load_img('woman.jpg'))\n",
    "image = np.array(image, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab color space is a 3-axis color system with dimension `L` for lightness and `a` green–red(-128, 128) and `b` blue–yellow(-128, 128) for the color dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = rgb2lab(1.0 / 255 * image)[:,:,0] # Get lightness only\n",
    "Y = rgb2lab(1.0 / 255 * image)[:,:,1:]\n",
    "Y /= 128\n",
    "X = X.reshape(1, 400, 400, 1)\n",
    "Y = Y.reshape(1, 400, 400, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None, None, 1)))  # (400, 400, 1)\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))  # (200, 200, 8)\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2)) # (100, 100, 16)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2)) # ( 50,  50, 32)\n",
    "model.add(UpSampling2D((2, 2)))    # (100, 100, 16)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))    # ( 200, 200, 32)\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))    # ( 400, 400, 16)\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, None, None, 8)     80        \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, None, None, 8)     584       \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, None, None, 16)    1168      \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, None, None, 16)    2320      \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, None, None, 32)    4640      \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, None, None, 16)    4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, None, None, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, None, None, 2)     290       \n",
      "=================================================================\n",
      "Total params: 32,202\n",
      "Trainable params: 32,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13464da0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,\n",
    "          Y,\n",
    "          batch_size=1,\n",
    "          epochs=1000,\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "0.000343502149917\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X, Y, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wuht\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "C:\\Users\\wuht\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(X)\n",
    "output *=128\n",
    "\n",
    "# Output colorizations\n",
    "cavas = np.zeros((400, 400, 3))\n",
    "cavas[:, :, 0] = X[0][:, :, 0]\n",
    "cavas[:, :, 1:] = output[0]\n",
    "imsave(\"img_woman.jpg\", lab2rgb(cavas))\n",
    "imsave(\"img_gray_version.png\", rgb2gray(lab2rgb(cavas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
